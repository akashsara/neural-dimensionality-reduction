{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "different-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occasional-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-construction",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "breathing-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"pca_v1\"\n",
    "test_data_path = \"data/datasets/questions-words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "former-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = f\"data/embeddings/trained/{experiment_name}.glove.6B.300d.txt\"\n",
    "converted_file = f\"data/embeddings/trained/{experiment_name}.glove.gensimFormat.6B.300d.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-minute",
   "metadata": {},
   "source": [
    "The word analogy task consists of questions like,  “a is to b as c is to?” The dataset contains 19,544 such questions, divided into a semantic subset and a syntactic subset. The semantic questions are typically analogies about people or places, like “Athens is to Greece as Berlin is to?”.  The syntactic questions are typically analogies about verb tenses or forms of adjectives, for example “dance is to dancing as fly is to?”.  To correctly answer the question, the model should uniquely identify the missing term, with only an exact correspondence counted as a correct match. We answer the question “a is to b as c is to?” by finding the word `d` whose representation `w_d` is closest to `w_b − w_a + w_c` according to the cosine similarity.\n",
    "\n",
    "https://nlp.stanford.edu/pubs/glove.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-intermediate",
   "metadata": {},
   "source": [
    "# Word Analogy Score Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-adrian",
   "metadata": {},
   "source": [
    "#1 Taking a quick glance at our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quarterly-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "with open(\"data/datasets/questions-words.txt\", \"r\") as fp:\n",
    "    x = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geographic-russell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[': capital-common-countries',\n",
       " 'Athens Greece Baghdad Iraq',\n",
       " 'Athens Greece Bangkok Thailand',\n",
       " 'Athens Greece Beijing China',\n",
       " 'Athens Greece Berlin Germany',\n",
       " 'Athens Greece Bern Switzerland',\n",
       " 'Athens Greece Cairo Egypt',\n",
       " 'Athens Greece Canberra Australia',\n",
       " 'Athens Greece Hanoi Vietnam',\n",
       " 'Athens Greece Havana Cuba']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split('\\n')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unnecessary-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-playlist",
   "metadata": {},
   "source": [
    "#2 Convert data into the format used by Gensim. [We use Gensim because it has a built-in function to calculate word analogy scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "residential-oriental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert GloVe Vectors into a format usable by gensim\n",
    "gensim.scripts.glove2word2vec.glove2word2vec(input_file, converted_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-incentive",
   "metadata": {},
   "source": [
    "#3 Load the formatted data & calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "large-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = gensim.models.keyedvectors.Word2VecKeyedVectors.load_word2vec_format(converted_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "musical-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = glove.evaluate_word_analogies(test_data_path, restrict_vocab=400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "terminal-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 66.82357756856324\n",
      "Semantic Accuracy: 60.99297423887588\n",
      "Syntactic Accuracy: 73.84147028977337\n"
     ]
    }
   ],
   "source": [
    "syn_correct = 0\n",
    "syn_incorrect = 0\n",
    "sem_correct = 0\n",
    "sem_incorrect = 0\n",
    "for item in results[1]:\n",
    "    correct = len(item['correct'])\n",
    "    incorrect = len(item['incorrect'])\n",
    "    if item['section'] == \"Total accuracy\":\n",
    "        print(f\"{item['section']}: {correct * 100/(correct+incorrect)}\")\n",
    "    elif item['section'][:4] == 'gram':\n",
    "        sem_correct += correct\n",
    "        sem_incorrect += incorrect\n",
    "    else:\n",
    "        syn_correct += correct\n",
    "        syn_incorrect += incorrect\n",
    "print(f\"Semantic Accuracy: {sem_correct * 100/(sem_correct+sem_incorrect)}\")\n",
    "print(f\"Syntactic Accuracy: {syn_correct * 100/(syn_correct+syn_incorrect)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-history",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
