{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "piano-artist"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "id": "piano-artist",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advisory-designation"
      },
      "source": [
        "import typing\n",
        "from typing import List, Tuple, Dict\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "id": "advisory-designation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDy2wkshvgGi"
      },
      "source": [
        "Colab-Specific Settings"
      ],
      "id": "sDy2wkshvgGi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQZjfi86vZLg",
        "outputId": "f7645bfc-6a5d-4975-ac1c-a6a956f14b22"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "id": "fQZjfi86vZLg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alert-mills"
      },
      "source": [
        "# Config"
      ],
      "id": "alert-mills"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "successful-convention"
      },
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "id": "successful-convention",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "molecular-foundation"
      },
      "source": [
        "colab_prefix = \"drive/MyDrive/CMPUT651_DL4NLP/\"\n",
        "\n",
        "source_embedding_dim = 300\n",
        "model_type = \"supervised_distilled\"\n",
        "version = 1\n",
        "embedding_dim = 300\n",
        "nn_hidden_size = 50\n",
        "\n",
        "experiment_name = f\"{model_type}_{source_embedding_dim}to{embedding_dim}_v{version}\"\n",
        "embedding_path = colab_prefix + f\"data/embeddings/trained/{experiment_name}.glove.6B.300d.txt\"\n",
        "model_output_path = colab_prefix + f\"models/ag_news_classifier_glove_{experiment_name}.pt\"\n",
        "# When using standard embeddings\n",
        "# embedding_path = colab_prefix + f\"data/embeddings/base/clipped.glove.6B.{embedding_dim}d.txt\"\n",
        "# model_output_path = colab_prefix + f\"models/ag_news_classifier_glove_clipped_{embedding_dim}d.pt\"\n",
        "\n",
        "freeze_embeddings = True\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "\n",
        "train_datapath = colab_prefix + \"data/datasets/ag_news/train.csv\"\n",
        "test_datapath = colab_prefix + \"data/datasets/ag_news/test.csv\"\n",
        "\n",
        "pad_tag = \"<PAD>\"\n",
        "unk_tag = \"<UNK>\""
      ],
      "id": "molecular-foundation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "institutional-alabama"
      },
      "source": [
        "gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if gpu else \"cpu\")"
      ],
      "id": "institutional-alabama",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62OAFRIK3Tfo",
        "outputId": "0242a80a-447b-469f-ef1e-39dd140efe20"
      },
      "source": [
        "# print(experiment_name)\n",
        "print(gpu, device)"
      ],
      "id": "62OAFRIK3Tfo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worst-chinese"
      },
      "source": [
        "# Load Embeddings"
      ],
      "id": "worst-chinese"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amazing-living"
      },
      "source": [
        "words = []\n",
        "vectors = []\n",
        "with open(embedding_path, \"r\", encoding=\"utf-8\") as fp:\n",
        "    for line in fp:\n",
        "        line = line.split()\n",
        "        word = line[0]\n",
        "        vector = np.asarray(line[1:], dtype='float32')\n",
        "        words.append(word)\n",
        "        vectors.append(vector)\n",
        "vectors = np.asarray(vectors)"
      ],
      "id": "amazing-living",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "charged-appraisal"
      },
      "source": [
        "Create an embedding for both \\<PAD> (all 0s) and \\<UNK> (average of all embeddings) tags."
      ],
      "id": "charged-appraisal"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "strong-atlanta"
      },
      "source": [
        "unk_embedding = np.mean(vectors, axis=0).reshape(1, -1)\n",
        "pad_embedding = np.zeros((1, vectors.shape[1]))"
      ],
      "id": "strong-atlanta",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "secondary-leather"
      },
      "source": [
        "vectors = torch.as_tensor(np.concatenate((vectors, pad_embedding, unk_embedding)))"
      ],
      "id": "secondary-leather",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "surgical-mongolia"
      },
      "source": [
        "Set up dictionaries for converting tags to indices, tokens to indices and vice-versa."
      ],
      "id": "surgical-mongolia"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "compliant-universal"
      },
      "source": [
        "token2index = {word: i for i, word in enumerate(words)}\n",
        "pad_token_index = len(token2index)\n",
        "unk_token_index = len(token2index) + 1\n",
        "token2index[pad_tag] = pad_token_index\n",
        "token2index[unk_tag] = unk_token_index\n",
        "\n",
        "index2token = {i: word for word, i in token2index.items()}"
      ],
      "id": "compliant-universal",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "following-tiffany"
      },
      "source": [
        "index2tag ={\n",
        "    0: \"World\",\n",
        "    1: \"Sports\",\n",
        "    2: \"Business\",\n",
        "    3: \"Sci/Tech\"\n",
        "}"
      ],
      "id": "following-tiffany",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intelligent-marijuana"
      },
      "source": [
        "# Load Data & Preprocess"
      ],
      "id": "intelligent-marijuana"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "absolute-poland"
      },
      "source": [
        "def sentence_to_indices(sentence, token2index, unk_token_index):\n",
        "    return [token2index.get(word, unk_token_index) for word in sentence]"
      ],
      "id": "absolute-poland",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "strange-watts"
      },
      "source": [
        "def indices_to_sentence(sentence, index2token):\n",
        "    return [index2token[int(index)] for index in sentence]"
      ],
      "id": "strange-watts",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "understanding-sunglasses"
      },
      "source": [
        "def pad_to_max_length(sentence, pad_token_index, max_length):\n",
        "    padding = [pad_token_index] * (max_length - len(sentence))\n",
        "    return sentence + padding"
      ],
      "id": "understanding-sunglasses",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "described-frame"
      },
      "source": [
        "def preprocess_data(df, token2index, pad_token_index, unk_token_index, title_max_length=0, desc_max_length=0):\n",
        "    print(\"Splitting & Lowercasing.\")\n",
        "    df['Title'] = df['Title'].str.lower().str.split()\n",
        "    df['Description'] = df['Description'].str.lower().str.split()\n",
        "    \n",
        "    # If no max length is specified, compute from data\n",
        "    if (title_max_length == desc_max_length) and (title_max_length == 0):\n",
        "        print(\"Computing Max Lengths.\")\n",
        "        title_max_length = df['Title'].apply(len).max()\n",
        "        desc_max_length = df['Description'].apply(len).max()\n",
        "    \n",
        "    # Convert tokens to indices\n",
        "    print(\"Transforming tokens into indices.\")\n",
        "    df['Title'] = df['Title'].apply(sentence_to_indices, args=(token2index, unk_token_index))\n",
        "    df['Description'] = df['Description'].apply(sentence_to_indices, args=(token2index, unk_token_index))\n",
        "    \n",
        "    # Pad data\n",
        "    print(\"Padding data.\")\n",
        "    df['Title'] = df['Title'].apply(pad_to_max_length, args=(pad_token_index, title_max_length))\n",
        "    df['Description'] = df['Description'].apply(pad_to_max_length, args=(pad_token_index, desc_max_length))\n",
        "    \n",
        "    # Convert to tensor\n",
        "    print(\"Splitting features & labels and converting to tensors.\")\n",
        "    data = df.to_dict(orient=\"records\")\n",
        "    titles = [x['Title'] for x in data]\n",
        "    descriptions = [x['Description'] for x in data]\n",
        "    features = [torch.as_tensor(titles), torch.as_tensor(descriptions)]\n",
        "    labels = torch.as_tensor([x['Class Index'] for x in data]) - 1 # We want 0-3 not 1-4\n",
        "    return features, labels, title_max_length, desc_max_length"
      ],
      "id": "described-frame",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "empty-linux"
      },
      "source": [
        "train = pd.read_csv(train_datapath)\n",
        "test = pd.read_csv(test_datapath)"
      ],
      "id": "empty-linux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quality-passing"
      },
      "source": [
        "train, val = train_test_split(\n",
        "    train, test_size=4000, stratify=train['Class Index'], random_state=seed\n",
        ")"
      ],
      "id": "quality-passing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "searching-robertson",
        "outputId": "862147c6-fff0-4c94-8531-832ae7a75e2c"
      },
      "source": [
        "len(train), len(val), len(test)"
      ],
      "id": "searching-robertson",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(116000, 4000, 7600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "conditional-nepal",
        "outputId": "96b85f4b-9c31-4404-beb6-e8b19f56e4bb"
      },
      "source": [
        "train_features, train_labels, title_max_length, desc_max_length = preprocess_data(\n",
        "    train, token2index, pad_token_index, unk_token_index\n",
        ")"
      ],
      "id": "conditional-nepal",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splitting & Lowercasing.\n",
            "Computing Max Lengths.\n",
            "Transforming tokens into indices.\n",
            "Padding data.\n",
            "Splitting features & labels and converting to tensors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "comparative-century",
        "outputId": "d80dd40e-f096-47a9-86e9-60a9a6c4dd59"
      },
      "source": [
        "val_features, val_labels, title_max_length, desc_max_lenght = preprocess_data(\n",
        "    val, token2index, pad_token_index, unk_token_index, title_max_length, desc_max_length\n",
        ")"
      ],
      "id": "comparative-century",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splitting & Lowercasing.\n",
            "Transforming tokens into indices.\n",
            "Padding data.\n",
            "Splitting features & labels and converting to tensors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "concerned-trademark",
        "outputId": "b828730b-e993-4d98-f91b-49235fd3bc5a"
      },
      "source": [
        "test_features, test_labels, title_max_length, desc_max_lenght = preprocess_data(\n",
        "    test, token2index, pad_token_index, unk_token_index, title_max_length, desc_max_length\n",
        ")"
      ],
      "id": "concerned-trademark",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splitting & Lowercasing.\n",
            "Transforming tokens into indices.\n",
            "Padding data.\n",
            "Splitting features & labels and converting to tensors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "behind-leather",
        "outputId": "0ff5f559-db85-41c4-d655-e240602ff5d7"
      },
      "source": [
        "title_max_length, desc_max_length"
      ],
      "id": "behind-leather",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 173)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "steady-somewhere"
      },
      "source": [
        "num_classes = len(train_labels.unique())"
      ],
      "id": "steady-somewhere",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cultural-columbus"
      },
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(train_features[0], train_features[1], train_labels)\n",
        "val_dataset = torch.utils.data.TensorDataset(val_features[0], val_features[1], val_labels)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_features[0], test_features[1], test_labels)"
      ],
      "id": "cultural-columbus",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "starting-brick"
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=gpu, \n",
        ")\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=gpu, \n",
        ")\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=gpu, \n",
        ")"
      ],
      "id": "starting-brick",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "micro-interest"
      },
      "source": [
        "# Model Time"
      ],
      "id": "micro-interest"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "illegal-denver"
      },
      "source": [
        "# https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, embeddings, embedding_dim, hidden_dim, num_classes, freeze_embeddings):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding.from_pretrained(embeddings, freeze=freeze_embeddings)\n",
        "        self.title_lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.desc_lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.classifier = nn.Linear(hidden_dim * 4, num_classes) # Since BiLSTM + 2 inputs\n",
        "\n",
        "    def forward(self, title, description):\n",
        "        # (batch_size, seq_len) -> (batch_size, seq_len, embedding_dim)\n",
        "        title_embedding = self.word_embeddings(title)\n",
        "        desc_embedding = self.word_embeddings(description)\n",
        "        # (batch_size, seq_len, embedding_dim) -> (batch_size, directions, hidden_dim) \n",
        "        _, (title_hidden, _) = self.title_lstm(title_embedding) \n",
        "        _, (desc_hidden, _) = self.desc_lstm(desc_embedding)\n",
        "        # (directions, batch_size, hidden_dim), (directions, batch_size, hidden_dim)\n",
        "        # -> (directions, batch_size, 2*hidden_dim)\n",
        "        out = torch.cat((title_hidden, desc_hidden), dim=2)\n",
        "        # (batch_size, directions, 2*hidden_dim) -> (batch_size, 2*hidden_dim*directions)\n",
        "        out = out.permute(1, 0, 2).flatten(start_dim=1)\n",
        "        # (batch_size, 2*hidden_dim*directions) -> (batch_size, num_classes)|\n",
        "        out = self.classifier(out)\n",
        "        # We use the CrossEntropyLoss so we aren't adding a softmax layer here\n",
        "        # Because in PyTorch CrossEntropyLoss combines a LogSoftmax with NLLLoss\n",
        "        # So we output raw logits\n",
        "        # Since we don't care about the confidences, we don't need a softmax during inference\n",
        "        # Since the highest value in a softmax will always be the highest value pre-softmax\n",
        "        return out"
      ],
      "id": "illegal-denver",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enhanced-environment"
      },
      "source": [
        "model = BiLSTM(vectors, embedding_dim, nn_hidden_size, num_classes, freeze_embeddings)\n",
        "model.double() # Since our embeddings are 32-dimensional\n",
        "model.to(device)\n",
        "loss_function = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "id": "enhanced-environment",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SpJyb6vMEJ9",
        "outputId": "f35e11a9-8c5d-470d-ade3-7545788fed0c"
      },
      "source": [
        "model"
      ],
      "id": "7SpJyb6vMEJ9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM(\n",
              "  (word_embeddings): Embedding(400002, 300)\n",
              "  (title_lstm): LSTM(300, 50, batch_first=True, bidirectional=True)\n",
              "  (desc_lstm): LSTM(300, 50, batch_first=True, bidirectional=True)\n",
              "  (classifier): Linear(in_features=200, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "defined-ground"
      },
      "source": [
        "# Training"
      ],
      "id": "defined-ground"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "matched-alarm",
        "outputId": "87147aa1-3f54-40e9-cc8b-37379a6ea66b"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    val_loss = 0\n",
        "    \n",
        "    # Training Loop\n",
        "    for iteration, batch in enumerate(tqdm(train_dataloader)):\n",
        "        # Move data to device\n",
        "        titles, descriptions, labels = batch\n",
        "        titles = titles.to(device)\n",
        "        descriptions = descriptions.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        predictions = model(titles, descriptions)\n",
        "        \n",
        "        # Calculate loss\n",
        "        batch_loss = loss_function(predictions, labels)\n",
        "        \n",
        "        # Backward pass\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update train loss\n",
        "        train_loss += batch_loss.item()\n",
        "    \n",
        "    # Validation Loop\n",
        "    with torch.no_grad():\n",
        "        for iteration, batch in enumerate(tqdm(val_dataloader)):\n",
        "            # Move data to device\n",
        "            titles, descriptions, labels = batch\n",
        "            titles = titles.to(device)\n",
        "            descriptions = descriptions.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(titles, descriptions)\n",
        "\n",
        "            # Calculate loss\n",
        "            batch_loss = loss_function(predictions, labels)\n",
        "\n",
        "            # Update train loss\n",
        "            val_loss += batch_loss.item()\n",
        "    \n",
        "    # Compute the average losses for this epoch\n",
        "    train_loss = train_loss / len(train_dataloader)\n",
        "    val_loss = val_loss / len(val_dataloader)\n",
        "    \n",
        "    \n",
        "    # Print Metrics\n",
        "    print(\n",
        "        f\"Epoch: {epoch+1}/{epochs}, Train Loss = {train_loss}, \\\n",
        "        Validation Loss = {val_loss}\"\n",
        "    )"
      ],
      "id": "matched-alarm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3625/3625 [02:16<00:00, 26.65it/s]\n",
            "100%|██████████| 125/125 [00:01<00:00, 73.34it/s]\n",
            "  0%|          | 0/3625 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/5, Train Loss = 0.30527777847563003,         Validation Loss = 0.253713835842478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3625/3625 [02:16<00:00, 26.51it/s]\n",
            "100%|██████████| 125/125 [00:01<00:00, 72.92it/s]\n",
            "  0%|          | 0/3625 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2/5, Train Loss = 0.2243793340084654,         Validation Loss = 0.23641120083268766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3625/3625 [02:19<00:00, 26.03it/s]\n",
            "100%|██████████| 125/125 [00:01<00:00, 70.61it/s]\n",
            "  0%|          | 0/3625 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3/5, Train Loss = 0.18909123871016834,         Validation Loss = 0.23164164714414195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3625/3625 [02:20<00:00, 25.80it/s]\n",
            "100%|██████████| 125/125 [00:01<00:00, 71.30it/s]\n",
            "  0%|          | 0/3625 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4/5, Train Loss = 0.15695351538103852,         Validation Loss = 0.23597222452108257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3625/3625 [02:20<00:00, 25.76it/s]\n",
            "100%|██████████| 125/125 [00:01<00:00, 71.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5/5, Train Loss = 0.12826177359975216,         Validation Loss = 0.2446062633396359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "human-annual"
      },
      "source": [
        "# Evaluation"
      ],
      "id": "human-annual"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "early-repeat",
        "outputId": "d8c7ef0a-d361-42f8-9cb5-a7899eac9d9e"
      },
      "source": [
        "model.eval()"
      ],
      "id": "early-repeat",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM(\n",
              "  (word_embeddings): Embedding(400002, 300)\n",
              "  (title_lstm): LSTM(300, 50, batch_first=True, bidirectional=True)\n",
              "  (desc_lstm): LSTM(300, 50, batch_first=True, bidirectional=True)\n",
              "  (classifier): Linear(in_features=200, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "choice-netscape",
        "outputId": "322794c0-5287-4204-fcdc-8a17dbb922c7"
      },
      "source": [
        "# Test Loop\n",
        "with torch.no_grad():\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for iteration, batch in enumerate(tqdm(test_dataloader)):\n",
        "        # Move data to device\n",
        "        titles, descriptions, labels = batch\n",
        "        titles = titles.to(device)\n",
        "        descriptions = descriptions.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = model(titles, descriptions).detach().cpu().numpy().argmax(axis=1)\n",
        "        \n",
        "        y_true.extend(labels.detach().cpu().numpy())\n",
        "        y_pred.extend(predictions)\n",
        "y_true = indices_to_sentence(y_true, index2tag)\n",
        "y_pred = indices_to_sentence(y_pred, index2tag)"
      ],
      "id": "choice-netscape",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:03<00:00, 76.47it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "divided-columbia",
        "outputId": "6099bce1-d01f-499f-f042-5828f8c67fe4"
      },
      "source": [
        "print(classification_report(y_true, y_pred, digits=4))"
      ],
      "id": "divided-columbia",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Business     0.8898    0.8800    0.8849      1900\n",
            "    Sci/Tech     0.8838    0.9047    0.8941      1900\n",
            "      Sports     0.9690    0.9705    0.9698      1900\n",
            "       World     0.9306    0.9174    0.9239      1900\n",
            "\n",
            "    accuracy                         0.9182      7600\n",
            "   macro avg     0.9183    0.9182    0.9182      7600\n",
            "weighted avg     0.9183    0.9182    0.9182      7600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quality-brazilian"
      },
      "source": [
        "# Save"
      ],
      "id": "quality-brazilian"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drawn-payday"
      },
      "source": [
        "torch.save(model.state_dict(), model_output_path)"
      ],
      "id": "drawn-payday",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxI5svCjelpw"
      },
      "source": [],
      "id": "oxI5svCjelpw",
      "execution_count": null,
      "outputs": []
    }
  ]
}