{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-coast",
   "metadata": {
    "id": "naked-coast"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-friend",
   "metadata": {
    "id": "desirable-friend"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mbMDMfDVa1qS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbMDMfDVa1qS",
    "outputId": "005dd9a7-5c95-4b26-9909-eb3ec9fdf3c8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-keyboard",
   "metadata": {
    "id": "stopped-keyboard"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-union",
   "metadata": {
    "id": "incoming-union"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-surfing",
   "metadata": {
    "id": "japanese-surfing"
   },
   "outputs": [],
   "source": [
    "colab_prefix = \"drive/MyDrive/CMPUT651_DL4NLP/\"\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "source_embedding_size = 300\n",
    "target_embedding_size = 100\n",
    "model_version = 1\n",
    "\n",
    "distill_knowledge = False\n",
    "\n",
    "if distill_knowledge:\n",
    "    model_type = \"supervised_distilled\"\n",
    "    target_embedding = colab_prefix + f\"data/embeddings/base/clipped.glove.6B.{target_embedding_size}d.txt\"\n",
    "else:\n",
    "    model_type = \"supervised\"\n",
    "\n",
    "source_embedding = colab_prefix + f\"data/embeddings/base/clipped.glove.6B.{source_embedding_size}d.txt\"\n",
    "experiment_name = f\"{model_type}_{source_embedding_size}to{target_embedding_size}_v{model_version}\"\n",
    "\n",
    "embedding_output_dir = colab_prefix + f\"data/embeddings/trained/{experiment_name}.glove.6B.300d.txt\"\n",
    "model_output_dir = colab_prefix + f\"models/{experiment_name}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-aquatic",
   "metadata": {
    "id": "killing-aquatic"
   },
   "outputs": [],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-solution",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clinical-solution",
    "outputId": "648cf3bc-84d3-411f-d78b-95bafd5b90c7"
   },
   "outputs": [],
   "source": [
    "print(gpu, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-browser",
   "metadata": {
    "id": "hollow-browser"
   },
   "source": [
    "# Load & Prepare Embeddings for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-career",
   "metadata": {
    "id": "catholic-career"
   },
   "outputs": [],
   "source": [
    "def get_word_embeddings(dataset):\n",
    "    words = []\n",
    "    vectors = []\n",
    "    with open(dataset, \"r\", encoding='utf8') as fp:\n",
    "        for line in fp:\n",
    "            line = line.split()\n",
    "            word = line[0]\n",
    "            vector = np.asarray(line[1:], 'float32')\n",
    "            words.append(word)\n",
    "            vectors.append(vector)\n",
    "    vectors = torch.from_numpy(np.asarray(vectors))\n",
    "    return words, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-citation",
   "metadata": {
    "id": "textile-citation"
   },
   "outputs": [],
   "source": [
    "words, vectors = get_word_embeddings(source_embedding)\n",
    "if distill_knowledge:\n",
    "    target_words, target_vectors = get_word_embeddings(target_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-motion",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "civilian-motion",
    "outputId": "35afdbe9-9ddd-4595-925b-297c2e5027e3"
   },
   "outputs": [],
   "source": [
    "# No train-val-test split since we want an embedding for all the words in the vocab\n",
    "print(len(words), vectors.shape)\n",
    "if distill_knowledge:\n",
    "    print(len(target_words), target_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-insured",
   "metadata": {
    "id": "large-insured"
   },
   "outputs": [],
   "source": [
    "word2index = {word:i for i, word in enumerate(words)}\n",
    "index2word = {i:word for word, i in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-angle",
   "metadata": {
    "id": "professional-angle"
   },
   "outputs": [],
   "source": [
    "input_data = torch.as_tensor([word2index[word] for word in words])\n",
    "output_data = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-suggestion",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "automotive-suggestion",
    "outputId": "50b53a0c-5b8e-4d96-d657-ae7036fdad00"
   },
   "outputs": [],
   "source": [
    "input_data.shape, output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-gentleman",
   "metadata": {
    "id": "specified-gentleman"
   },
   "outputs": [],
   "source": [
    "num_embeddings = input_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-devices",
   "metadata": {
    "id": "american-devices"
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(input_data, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-lafayette",
   "metadata": {
    "id": "animal-lafayette"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-peeing",
   "metadata": {
    "id": "advance-peeing"
   },
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-summary",
   "metadata": {
    "id": "latin-summary"
   },
   "outputs": [],
   "source": [
    "class SupervisedModel(nn.Module):\n",
    "    def __init__(self, num_embeddings, source_embedding_size, target_embedding_size, target_embedding=None):\n",
    "        super().__init__()\n",
    "        if target_embedding is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(target_embedding, freeze=False)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(num_embeddings, target_embedding_size)\n",
    "        self.linear = nn.Linear(in_features=target_embedding_size, out_features=source_embedding_size)\n",
    "        self.activation = nn.Tanh()\n",
    "    \n",
    "    def forward(self, features):\n",
    "        embedding = self.embedding(features)\n",
    "        return self.activation(self.linear(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-script",
   "metadata": {
    "id": "quarterly-script"
   },
   "outputs": [],
   "source": [
    "if distill_knowledge:\n",
    "    model = SupervisedModel(num_embeddings, source_embedding_size, target_embedding_size, target_vectors).to(device)\n",
    "else:\n",
    "    model = SupervisedModel(num_embeddings, source_embedding_size, target_embedding_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-london",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "referenced-london",
    "outputId": "5d2c2b03-7668-4393-a992-e49b96313742"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-xerox",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "individual-xerox",
    "outputId": "9328f2ca-d863-4615-e1d1-9f7ced22b035",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_train_loss = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Training Loop\n",
    "    for iteration, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # Reset gradients back to zero for this iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get inputs and outputs\n",
    "        batch_inputs, batch_outputs = batch\n",
    "        \n",
    "        # Move data to device\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_outputs = batch_outputs.to(device)\n",
    "\n",
    "        # Run our model & get outputs\n",
    "        outputs = model(batch_inputs)\n",
    "\n",
    "        # Calculate reconstruction loss\n",
    "        batch_loss = criterion(outputs, batch_outputs)\n",
    "                  \n",
    "        # Backprop\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        # Update our optimizer parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Add the batch's loss to the total loss for the epoch\n",
    "        train_loss += batch_loss.item()\n",
    "            \n",
    "    # Compute the average losses for this epoch\n",
    "    train_loss = train_loss / len(train_dataloader)\n",
    "    all_train_loss.append(train_loss)\n",
    "    \n",
    "    # Print Metrics\n",
    "    print(\n",
    "        f\"\\nEpoch: {epoch+1}/{epochs}\\nTrain Loss = {train_loss}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Xq6PL6Wiv1q",
   "metadata": {
    "id": "1Xq6PL6Wiv1q"
   },
   "source": [
    "# Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_cXtTarXivlR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "_cXtTarXivlR",
    "outputId": "37d70da4-b2f8-4a8d-c4a8-87432ea66c17"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 10\n",
    "plt.figure(figsize=(8, 6), dpi=100)\n",
    "ax = plt.subplot()\n",
    "plt.xlim(0, epochs)\n",
    "plt.plot(list(range(epochs)), [x for x in all_train_loss], label=\"Train Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-stanley",
   "metadata": {
    "id": "imported-stanley"
   },
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-dayton",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "graphic-dayton",
    "outputId": "853f044b-0265-48bc-b483-bfd7d93d129b"
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-version",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sophisticated-version",
    "outputId": "9f636968-82fc-449a-d5dd-428484d06b50"
   },
   "outputs": [],
   "source": [
    "latent_vectors = {}\n",
    "with torch.no_grad():\n",
    "    for i, word in enumerate(tqdm(input_data)):\n",
    "        latent_vectors[index2word[int(word)]] = model.embedding(word.to(device)).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-handling",
   "metadata": {
    "id": "inside-handling",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-projector",
   "metadata": {
    "id": "suited-projector"
   },
   "outputs": [],
   "source": [
    "latent_vectors['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-mount",
   "metadata": {
    "id": "honest-mount"
   },
   "source": [
    "# Save Model & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-eclipse",
   "metadata": {
    "id": "political-eclipse"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-refrigerator",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "blond-refrigerator",
    "outputId": "48322226-82c1-4d33-8418-704f63fc9f45"
   },
   "outputs": [],
   "source": [
    "# Need to convert the embeddings into the glove format\n",
    "# word dim1 dim2 dim3 dim4 ... dimX\n",
    "lines = []\n",
    "for i, (word, vector) in tqdm(enumerate(latent_vectors.items())):\n",
    "    line = [word] + [str(x) for x in vector.tolist()]\n",
    "    lines.append(' '.join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-conservative",
   "metadata": {
    "id": "wooden-conservative"
   },
   "outputs": [],
   "source": [
    "with open(embedding_output_dir, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KAfsrckrxxq2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "KAfsrckrxxq2",
    "outputId": "a5e5065e-f0dd-44d0-bca9-1bf2308e2e9a"
   },
   "outputs": [],
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fIyGLhloQvSL",
   "metadata": {
    "id": "fIyGLhloQvSL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "supervised.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}