{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-union",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.05\n",
    "validation_split = 0.05\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "input_size = 300\n",
    "bottleneck_size = 200\n",
    "\n",
    "use_hidden_layer = False\n",
    "hidden_size = 225\n",
    "\n",
    "noise_type = 'masking' # additive, masking or none\n",
    "noise_factor = 0.3\n",
    "\n",
    "# Only when noise_type = masking\n",
    "alpha_weight = 1 \n",
    "beta_weight = 0.5\n",
    "\n",
    "experiment_name = f\"autoencoder_300to{bottleneck_size}_v3.1\"\n",
    "dataset = \"data/embeddings/base/clipped.glove.6B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpu, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-browser",
   "metadata": {},
   "source": [
    "# Load & Prepare Embeddings for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "vectors = []\n",
    "with open(dataset, \"r\", encoding='utf8') as fp:\n",
    "    for line in fp:\n",
    "        line = line.split()\n",
    "        word = line[0]\n",
    "        vector = np.asarray(line[1:], 'float32')\n",
    "        words.append(word)\n",
    "        vectors.append(vector)\n",
    "vectors = torch.from_numpy(np.asarray(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = int(test_split * len(words))\n",
    "validation_split = int(validation_split* len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(words), vectors.shape)\n",
    "print(test_split, validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, test_vectors, train_words, test_words = train_test_split(\n",
    "    vectors, words, test_size=test_split, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, validation_vectors, train_words, validation_words = train_test_split(\n",
    "    train_vectors, train_words, test_size=validation_split, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors.shape, validation_vectors.shape, test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We don't actually use these words since the model doesn't care about them.\n",
    "# We just compute them in case we want to check some particular word or something.\n",
    "len(train_words), len(validation_words), len(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_vectors, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=gpu\n",
    ")\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    validation_vectors, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=gpu\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_vectors, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-peeing",
   "metadata": {},
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderWithoutHiddenLayer(nn.Module):\n",
    "    def __init__(self, input_size, bottleneck_size):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(in_features=input_size, out_features=bottleneck_size)\n",
    "        self.encoder_activation = nn.Tanh()\n",
    "        \n",
    "        self.decoder = nn.Linear(in_features=bottleneck_size, out_features=input_size)\n",
    "        self.decoder_activation = nn.Tanh()\n",
    "        \n",
    "        self.decoder.weight = nn.Parameter(self.encoder.weight.transpose(0,1))\n",
    "    \n",
    "    def forward(self, features):\n",
    "        latent_representation = self.encoder_activation(self.encoder(features))\n",
    "        reconstructed_input = self.decoder_activation(self.decoder(latent_representation))\n",
    "        return reconstructed_input\n",
    "    \n",
    "    def encode(self, features):\n",
    "        return self.encoder_activation(self.encoder(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderWithHiddenLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bottleneck_size):\n",
    "        super().__init__()\n",
    "        self.encoder_input = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        self.encoder_input_activation = nn.ReLU(True)\n",
    "        self.encoder_hidden = nn.Linear(in_features=hidden_size, out_features=bottleneck_size)\n",
    "        self.encoder_hidden_activation = nn.Tanh()\n",
    "        \n",
    "        self.decoder_hidden = nn.Linear(in_features=bottleneck_size, out_features=hidden_size)\n",
    "        self.decoder_hidden_activation = nn.ReLU(True)\n",
    "        self.decoder_output = nn.Linear(in_features=hidden_size, out_features=input_size)\n",
    "        self.decoder_output_activation = nn.Tanh()\n",
    "        \n",
    "        self.decoder_hidden.weight = nn.Parameter(self.encoder_hidden.weight.transpose(0,1))\n",
    "        self.decoder_output.weight = nn.Parameter(self.encoder_input.weight.transpose(0,1))\n",
    "        \n",
    "        self.encoder = [\n",
    "            self.encoder_input, self.encoder_input_activation, self.encoder_hidden, self.encoder_hidden_activation\n",
    "        ]\n",
    "        self.decoder = [\n",
    "            self.decoder_hidden, self.decoder_hidden_activation, self.decoder_output, self.decoder_output_activation\n",
    "        ]\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # Encoder\n",
    "        for layer in self.encoder:\n",
    "            features = layer(features)\n",
    "        # Decoder\n",
    "        for layer in self.decoder:\n",
    "            features = layer(features)\n",
    "        return features\n",
    "    \n",
    "    def encode(self, features):\n",
    "        for layer in self.encoder:\n",
    "            features = layer(features)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_hidden_layer:\n",
    "    model = AutoEncoderWithHiddenLayer(input_size, hidden_size, bottleneck_size).to(device)\n",
    "else:\n",
    "    model = AutoEncoderWithoutHiddenLayer(input_size, bottleneck_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masking_noise(shape, amount):\n",
    "    \"\"\"\n",
    "    Shape: Shape of the noise matrix\n",
    "    Amount: The amount of the matrix that should be masked (zero'd) out\n",
    "    \"\"\"\n",
    "    mask = np.ones(shape)\n",
    "    amount = int(shape[0] * amount)\n",
    "    mask[:, :amount] = 0\n",
    "    for x in mask:\n",
    "        np.random.shuffle(x)\n",
    "    return torch.from_numpy(mask.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-xerox",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    validation_loss = 0\n",
    "    \n",
    "    # Training Loop\n",
    "    for iteration, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # Reset gradients back to zero for this iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if noise_type == 'additive':\n",
    "            # Add noise to our inputs\n",
    "            noise = torch.randn(batch.shape) * noise_factor\n",
    "            noisy_batch = torch.clamp(batch + noise, -1, +1)\n",
    "            \n",
    "            # Move batch to device\n",
    "            noisy_batch = noisy_batch.to(device)\n",
    "\n",
    "            # Run our model & get outputs\n",
    "            outputs = model(noisy_batch)\n",
    "            \n",
    "            # Calculate reconstruction loss\n",
    "            batch_loss = criterion(outputs, batch)\n",
    "        elif noise_type == 'masking':\n",
    "            # Create masking noise and mask inputs\n",
    "            noise = create_masking_noise(batch.shape, noise_factor)\n",
    "            masked_batch = np.multiply(batch, noise)\n",
    "            \n",
    "            # Move batch to device\n",
    "            masked_batch = masked_batch.to(device)\n",
    "            \n",
    "            # Run model & get outputs\n",
    "            outputs = model(masked_batch)\n",
    "            \n",
    "            # Calculate reconstruction loss\n",
    "            # We calculate the error for the masked dimensions separately from the unmasked ones\n",
    "            # We can then assign a weight to each of the two components \n",
    "            unmasked_error = criterion(outputs * noise, masked_batch)\n",
    "            masked_error = criterion(outputs * (1 - noise), batch * (1 - noise))\n",
    "            batch_loss = (alpha_weight * masked_error) + (beta_weight * unmasked_error)\n",
    "        else:\n",
    "            # Move batch to device\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Run our model & get outputs\n",
    "            outputs = model(batch)\n",
    "            \n",
    "            # Calculate reconstruction loss\n",
    "            batch_loss = criterion(outputs, batch)\n",
    "                  \n",
    "        # Backprop\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        # Update our optimizer parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Add the batch's loss to the total loss for the epoch\n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "    # Validation Loop\n",
    "    with torch.no_grad():\n",
    "        for iteration, batch in enumerate(tqdm(validation_dataloader)):\n",
    "            # Move batch to device\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Run our model & get outputs\n",
    "            outputs = model(batch)\n",
    "\n",
    "            # Calculate reconstruction loss\n",
    "            batch_loss = criterion(outputs, batch)\n",
    "\n",
    "            # Add the batch's loss to the total loss for the epoch\n",
    "            validation_loss += batch_loss.item()\n",
    "    \n",
    "    # Compute the average losses for this epoch\n",
    "    train_loss = train_loss / len(train_dataloader)\n",
    "    validation_loss = validation_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Print Metrics\n",
    "    print(\n",
    "        f\"Epoch: {epoch+1}/{epochs}, Train Reconstruction Loss = {train_loss}, \\\n",
    "        Validation Reconstruction Loss = {validation_loss}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-kingston",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = 0\n",
    "\n",
    "# Testing Loop\n",
    "with torch.no_grad():\n",
    "    for iteration, batch in enumerate(tqdm(test_dataloader)):\n",
    "        # Move batch to device\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Run our model & get outputs\n",
    "        outputs = model(batch)\n",
    "\n",
    "        # Calculate reconstruction loss\n",
    "        batch_loss = criterion(outputs, batch)\n",
    "\n",
    "        # Add the batch's loss to the total loss for the epoch\n",
    "        reconstruction_loss += batch_loss.item()\n",
    "\n",
    "# Compute the average losses for this epoch\n",
    "reconstruction_loss = reconstruction_loss / len(test_dataloader)\n",
    "\n",
    "# Print Metrics\n",
    "print(\n",
    "    f\"Test Reconstruction Loss = {reconstruction_loss}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-stanley",
   "metadata": {},
   "source": [
    "# Generate Latent Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = {}\n",
    "with torch.no_grad():\n",
    "    for i, (word, vector) in enumerate(tqdm(zip(words, vectors))):\n",
    "        latent_vectors[word] = model.encode(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-handling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-mount",
   "metadata": {},
   "source": [
    "# Save Model & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"models/{experiment_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert the latent embeddings into the glove format\n",
    "# word dim1 dim2 dim3 dim4 ... dimX\n",
    "lines = []\n",
    "for i, (word, vector) in tqdm(enumerate(latent_vectors.items())):\n",
    "    line = [word] + [str(x) for x in vector.tolist()]\n",
    "    lines.append(' '.join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/embeddings/trained/{experiment_name}.glove.6B.300d.txt\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-desire",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
